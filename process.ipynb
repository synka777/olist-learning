{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f81c0f",
   "metadata": {},
   "source": [
    "## Processing ETL des sets de donnÃ©es Olist\n",
    "\n",
    "#### 1. Nettoyage: OpÃ©rations globales Ã  tous les fichiers source\n",
    "\n",
    "Dans cette partie je gÃ¨re les nettoyages qui peuvent potentiellement s'appliquer Ã  toutes les tables, sans faire de traitement spÃ©cifique pour telle ou telle table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08bc36cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading olist_orders_dataset.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n",
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n",
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n",
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading olist_products_dataset.csv...\n",
      "Loading olist_order_items_dataset.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product_category_name_translation.csv...\n",
      "Loading olist_sellers_dataset.csv...\n",
      "Loading olist_geolocation_dataset.csv...\n",
      "Loading olist_order_reviews_dataset.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n",
      "/home/mathieu/prj/olist-learning/scripts/utils.py:13: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df[col] = pd.to_datetime(df[col],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading olist_order_payments_dataset.csv...\n",
      "Loading olist_customers_dataset.csv...\n"
     ]
    }
   ],
   "source": [
    "# Import de dÃ©pendances et chargement des datasets en mÃ©moire vive\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scripts.utils import clean_data\n",
    "\n",
    "data = {}\n",
    "\n",
    "rt = Path('./data')\n",
    "file_paths = os.listdir(rt)\n",
    "csv_file_paths = [f for f in file_paths if f.endswith('.csv')]\n",
    "for csv_path in csv_file_paths:\n",
    "    print(f'Loading {csv_path}...')\n",
    "    df = pd.read_csv(rt.joinpath(csv_path))\n",
    "    df = clean_data(df) # Utilisation d'un heler gÃ©nÃ©rique de nettoyage\n",
    "    source = csv_path.replace('olist_', '').replace('.csv', '').replace('_dataset', '')\n",
    "    data[source] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70be187",
   "metadata": {},
   "source": [
    "#### 2. Nettoyage: Cas spÃ©cifiques\n",
    "\n",
    "Dans cette partie du notebook j'applique des netoyages plus spÃ©cifiques, sur des tables en particulier:\n",
    "- customers: suppression de doublons et d\"une colonne non utilisÃ©e => EDIT: Pas une bonne idÃ©e, je commente\n",
    "- geolocation et customers: normalisation des noms de ville pour cohÃ©rence des Ã©ventuels PKI qui utiliseraient les noms de ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des doublons de donnÃ©es table customers\n",
    "# data['customers'].drop_duplicates(subset=['customer_unique_id'], keep='first')\n",
    "# data['customers'] = data['customers'].drop(columns=['customer_unique_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1e48d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import norm\n",
    "\n",
    "# Normalise les noms de villes\n",
    "data['geolocation']['geolocation_city'] = data['geolocation']['geolocation_city'].apply(norm)\n",
    "data['customers']['customer_city'] = data['customers']['customer_city'].apply(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8045d4",
   "metadata": {},
   "source": [
    "#### 3. Transformations\n",
    "\n",
    "La transformation principale que j'ai imaginÃ©e sur ce cas d'Ã©cole a Ã©tÃ© d'ajouter les traductions de noms de catÃ©gories directement dans la table produits.\n",
    "\n",
    "Le but Ã©tant de simplifier les requÃªtes devant filtrer ou grouper par catÃ©gorie, cela Ã©vite d'avoir Ã  faire des jointures ultÃ©rieures pour rÃ©cupÃ©rer les traductions.\n",
    "\n",
    "Au dÃ©part j'ai mÃªme considÃ©rÃ© faire cela pour cmplÃ¨tement supprimer la table de traductions, mais j'ai dÃ©cidÃ© de la garder, dans le scÃ©nario oÃ¹ un utilisateur brÃ©silien aurait besoin de faire des requÃªtes sur la base de donnÃ©es: dans ce cas les jointures resteront faisables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce17c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_category_name product_category_name_en\n",
      "0             perfumaria                perfumery\n",
      "1                  artes                      art\n",
      "2          esporte_lazer           sports_leisure\n",
      "3                  bebes                     baby\n",
      "4  utilidades_domesticas               housewares\n"
     ]
    }
   ],
   "source": [
    "# Transformation de la table des produits\n",
    "\n",
    "# Merge des dataframes pour ajouter la traduction anglaise et Ã©viter les jointures\n",
    "data['products'] = data['products'].merge(\n",
    "    data['product_category_name_translation'],\n",
    "    how='left', # Type de jointure : left pour conserver tous les produits mÃªme sans traduction\n",
    "    left_on='product_category_name', # ClÃ© de jointure dans la table des produits\n",
    "    right_on='product_category_name' # ClÃ© de jointure dans la table de traduction\n",
    ")\n",
    "\n",
    "# Renommer la nouvelle colonne pour Ã©viter les conflits\n",
    "data['products'].rename(columns={'product_category_name_english': 'product_category_name_en'},\n",
    "                inplace=True)\n",
    "\n",
    "# RÃ©sultat final\n",
    "print(data['products'][['product_category_name', 'product_category_name_en']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59c588",
   "metadata": {},
   "source": [
    "#### 4. Chargement en base de donnÃ©es\n",
    "\n",
    "\n",
    "Pour le chargement j'ai choisi d'utiliser sqlite3 pour gÃ©rer la partie crÃ©ation de tables en manuel avec des scripts SQL; Ã§a permet d'avoir une crÃ©ation de tables qui inclue directement toutes les contraintes nÃ©cessaires, et c'est plus simple que d'utiliser la syntaxe de sqlalchemy, qui ajoute une couche d'abstraction supplÃ©mentaire Ã  SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2bdde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "DB_PATH = \"./olist.db\"\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Ouverture et exÃ©cution du script SQL de crÃ©ation de schÃ©ma de base de donnÃ©es\n",
    "    with open('./scripts/schema.sql', 'r') as f:\n",
    "        schema_sql = f.read()\n",
    "        cur.executescript(schema_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfde9104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donnÃ©es nettoyÃ©es/transformÃ©es dans la base de donnÃ©es SQLite\n",
    "for table_name, df in data.items():\n",
    "    df.to_sql(table_name, con=conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f39df0",
   "metadata": {},
   "source": [
    "### 5. DÃ©veloppement d'indicateurs de perfomances\n",
    "\n",
    "#### ðŸ’° Ventes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1546356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 633 rows in 0.905s\n"
     ]
    }
   ],
   "source": [
    "from scripts.utils import benchmark_query\n",
    "\n",
    "with open('./scripts/pki/sales/daily.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "    print(benchmark_query(sql_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f57de4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './scripts/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m benchmark_query\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./scripts/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32m      4\u001b[39m     sql_script = f.read()\n",
      "\u001b[32m      5\u001b[39m     benchmark_query(sql_script)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/olist-learning/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n",
      "\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    342\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: './scripts/'"
     ]
    }
   ],
   "source": [
    "from scripts.utils import benchmark_query\n",
    "\n",
    "with open('./scripts/pki/sales/monthly.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "    benchmark_query(sql_script)\n",
    "    print(benchmark_query(sql_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9e07b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './scripts/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m benchmark_query\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./scripts/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32m      4\u001b[39m     sql_script = f.read()\n",
      "\u001b[32m      5\u001b[39m     benchmark_query(sql_script)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/olist-learning/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n",
      "\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    342\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: './scripts/'"
     ]
    }
   ],
   "source": [
    "from scripts.utils import benchmark_query\n",
    "\n",
    "with open('./scripts/pki/sales/yearly.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "    print(benchmark_query(sql_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b1ed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './scripts/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m benchmark_query\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./scripts/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32m      4\u001b[39m     sql_script = f.read()\n",
      "\u001b[32m      5\u001b[39m     benchmark_query(sql_script)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/olist-learning/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n",
      "\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    342\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: './scripts/'"
     ]
    }
   ],
   "source": [
    "from scripts.utils import benchmark_query\n",
    "\n",
    "with open('./scripts/pki/sales/previous_year_comparison.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "    print(benchmark_query(sql_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ea1c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './scripts/'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mIsADirectoryError\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n",
      "\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m benchmark_query\n",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./scripts/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32m      4\u001b[39m     sql_script = f.read()\n",
      "\u001b[32m      5\u001b[39m     benchmark_query(sql_script)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/olist-learning/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:344\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n",
      "\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n",
      "\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[32m    339\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    341\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    342\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[31mIsADirectoryError\u001b[39m: [Errno 21] Is a directory: './scripts/'"
     ]
    }
   ],
   "source": [
    "from scripts.utils import benchmark_query\n",
    "\n",
    "with open('./scripts/pki/sales/top10.sql', 'r') as f:\n",
    "    sql_script = f.read()\n",
    "    print(benchmark_query(sql_script))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
